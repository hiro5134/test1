<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# [My kicks](#mykicks)

## <a href="#index">Index</a><a id="index"></a>
* [Chapter 1](#cp1)
    * [Library](#lib)
    * [Higher API](#higherapi)
* [Chapter 2](#cp2)
    * [活性化関数](#mlp)
    * [万能近似定理 Universal Approximation Theorem](#uat)
    * [出力ユニットとタスク](#unit)
    * [損失関数](#loss)
* [Chapter 3](#cp3)
    * [バッチ処理](#batch)
    * [ミニバッチ処理](#minibatch)
    * [最適化手法](#adapt)
        * [最急降下法](#gd)
        * [確率的最急降下法](#sgd)
        * [モメンタム](#momentum)
        * [ネステロフのモメンタム](#momentum2)
        * [AdaGrad](#adagrad)
        * [RMSProp](#rmsp)
        * [Adam](#adam)
* [Chapter 4](#cp4)

## <a id = "cp1">Chapter 1</a>
1. ## <a id="lib">Library</a>
    | Lib | Graph | Company | Year | memo |
    | - | - | - | - | - |
    | TensorFlow | Define and Run | Google | 2015 | 計算グラフを自分で定義 |
    | Chainer | Define by Run | Preferred Networks | 2015 | 2019年開発終了 |
    | PyTorch | Define by Run | Facebook | 2016 | 計算方法がnumpyに似てる |
    | TensorFlow 2 | Define by Run | Google | 2019 | シンプルな実装可能 |
    | Apache MXNet | Define and Run <br> Define by Run| AWS | 2017 | 静的・動的どちらも可能|
    | Caffe2 | Define and Run | Facebook | 2017 | 2018年PyTorchへ統合 |
    | Congnitive Toolkit (CNTK) | Define and Run | Microsoft | 2016 | 音声認識特化 |
    | theano | Define and Run | モントリオール大学 | 2007 | 2017年開発終了 |
1. ## <a id="higherapi">Higher API</a>
    | API | Company | Year | memo |
    | - | - | - | - |
    | Keras |  Google | 2015 | TF用のAPI(TF2から標準API) |
    | Gluon | AWS, Microsoft | 2017 | MXNet用のAPI |

## <a id = "cp2">Chapter 2</a>
1. ## <a id="activation">活性化関数</a>
    中間層の表現を非線形にするため．  
    表現力の向上
    - step関数  
        勾配が0になり最適化が難しい
    - sigmoid関数
        0~1  
        勾配消失が起こり，中間層の最適化に不向き
    - softmax関数  
        複数の入力を扱える  
        出力の合計が1
        勾配消失が起こり，中間層の最適化に不向き
    - tanh関数  
        -1~1
        勾配消失が起こり，中間層の最適化に不向き
    - ReLU関数  
        x>0で勾配が計算可能で勾配が消失しない  
        x<0での勾配を計算するために以下の派生が存在  
        - Leaky ReLU  
            x<0に緩やかな傾き
        - Randomized ReLU  
            x<0の傾きをランダムに変更(予測時は平均値に固定)
        - Parametric ReLU  
            x<0の傾きを学習
    - MAXOUT関数  
        ReLU関数の一般化  
        要素数kのグループから各グループの最大値を抽出  
        ReLU関数や二次関数などに近似可能
        ReLu関数よりも表現力が高く勾配が消えない   
        活性化関数自体を学習

1. ## <a id="uat">万能近似定理 Universal Approximation Theorem</a>
    3層モデルの中間層のノードを極限まで増やせばあらゆる関数を近似可能  
    →現実的でない  
    →活性化関数により，層を横に伸ばすことで表現力をあげられる（計算コストも少なく収まる）  
    →万能近似定理+活性化関数でDLが飛躍

1. ## <a id="unit">出力ユニットとタスク</a>
    | Task |  | Unit | Activation Func. | Loss Func. | Probability | memo |
    | - | - | - | - | - | - | - |
    | 回帰 |  | 線形ユニット | 恒等関数 | MSE | ガウス分布 | 連続値を予測<br>目的変数（連続値）の分布をガウス分布と仮定<br>出力値は目的変数の分布（条件付きガウス分布）の平均値を返そうとする|
    | 分類 | 二値分類 | シグモイドユニット | sigmoid関数 | Binary Cross Entropy | ベルヌーイ分布 | ラベルが1である確率を予測<br>目的変数の分布は二項分布<br>ベルヌーイ分布を出力|
    | | 多値分類 | softmaxユニット | softmax関数 | Cross Entropy | | ラベルごとに確率を予測 |

1. ## <a id="loss">損失関数</a>
    尤度の最大化　損失関数の最小化　となるように設計

## <a id = "cp3">Chapter 3</a>
1. ## <a id="batch">バッチ処理</a>
    オンライン学習 入力１つ
    バッチ処理　入力nこ　あらゆる場所がn次元になる
        sum撮るときはdim=1
        基本サンプルが行，説明変数が列なので列方向に足していくことでサンプルごとのsumが取れる

1. ## <a id="minibatch">ミニバッチ処理</a>
    バッチ処理　データ数が膨大であれば計算量も膨大にありパラメータの更新が遅い
    →データを分割してバッチ処理をする
    | Task | 勾配推定 | 収束速度 |
    | - | - | - |
    | バッチサイズ大 | 正確 | 遅い |
    | バッチサイズ小 | 誤差を高める | 早い |
    　　
1. ## <a id="adapt">最適化手法</a>
    1. ## <a id="gd">最急降下法 Gradient descent</a>
        全体像はわからないが，その地点での最短経路方向に更新
        →求めた勾配方向とは逆向きに，その大きさ*η(学習率)を更新

        最急降下法ではlocal minimaに陥る可能性

        η小　時間がかかる　最適な場所を見つけられる可能性
        η大　早い　値がブレて最適な場所を見つけられない可能性
    1. ## <a id="sgd">SGD 確率的勾配降下法 stochastic gradient descent</a>
        確率的な山の一地点で最短経路方向に更新
        ミニバッチ抽出にランダム性を持たせ，損失関数が確率的になる

        最急降下法の弱点を克服
        （これまで）学習率を確率的に変化
        →損失関数が複雑すぎてうまくいかない

        そこでSDGはデータを確率的に変える
        →データをシャッフルして，それぞれの損失関数の挙動を変える
        →あるミニバッチでは上がり，他方では下がる，などができ最適な場所を見つけられる

        $$
          {\bm W} = {\bm W} - \eta\frac{\partial L}{\partial {\bm W}}
        $$

        一方で損失関数の形状が急峻な場合，振動してしまう

    1. ## <a id="momentum">モメンタム</a>
        移動平均を導入（慣性項）
        精度を保ちつつ，収束速度を早くする

        SDG＋慣性の法則→モメンタム

    1. ## <a id="momentum2">ネステロフのモメンタム</a>
        慣性項なしで更新した場合に慣性項をたしあわせ
        →ブレーキの役割

    1. ## <a id="adagrad">AdaGrad</a>
        過去の購買の二乗和を記憶して学習率を調整

        今までの勾配が大きい　学習率小さく更新
        今までの勾配が小さい　学習率大きく更新

        問題点
        学習率が0になる可能性
        →局所解

    1. ## <a id="rmsp">RMSProp</a>
        古い情報を忘れ，新しい情報を反映しやすくした

    1. ## <a id="adam">Adam</a>
        現在のスダンダード

        イテレーション数でバイアス補正
        →初期段階の不安定さを解消

        ${\bm m}$は速度の概念
        Momentum SDGにおける${\bm v}$
        減衰率$\beta_1$で過去の勾配情報${\bm m}$と現在の勾配情報$\frac{\partial L}{\partial {\bm W}}$を調整する
        $$
          {\bm m} = \beta_1{\bm m} + (1 - \beta_1)\frac{\partial L}{\partial {\bm W}}
        $$

        ${\bm v}$過去の勾配の二乗和
        $$
          {\bm v} = \beta_2{\bm v} + (1 - \beta_2)\left(\frac{\partial L}{\partial {\bm W}}\right)^2
        $$

        ${\bm m}, {\bm v}$は減衰率によって減衰させられた勾配の(二乗)和
        0.9が設定されると，勾配の１割しか学習に使われない
        下記で調整
        $$
          {\hat{\bm m}} = \frac{{\bm m}}{1-\beta_1^t},
          {\hat{\bm v}} = \frac{{\bm v}}{1-\beta_2^t}
        $$
        tはイテレーション数
        $\beta^t$は0に漸近，$\frac{1}{1-\beta^t}$は1に漸近
        ${\bm m, v}$に過去の情報が蓄積されるまでは勾配を利用
        更新が進むにつれ上式の影響は薄れる

        ${\hat{\bm m}},{\hat{\bm v}}$を用いてパラメータ${\bm W}$を更新
        $\epsilon$は微小項（0除算のため）
        $$
          {\bm W} = -\eta\frac{{\hat{\bm m}}}{\sqrt{{\hat{\bm v}}}+\epsilon}
        $$

        以上を総合して
        $$
          {\bm W} = -\eta\frac{\sqrt{1-\beta_2^t}}{1-\beta_1^t}
          \frac{{\bm m}}{\sqrt{{\bm v}}+\epsilon}
        $$

## <a id = "cp4">Chapter 4</a>
1. ## <a id="">勾配消失問題</a>
    backpropagationにて1より小さい値の掛け算により入力層に近い隠れ層に伝わる勾配がほぼ0になる

    activationに用いられるsigmoidやtanhの微分値は基本＜1であるため

    勾配が小さい→更新がほぼない

    ReLUにより解決の道
    微分値→常に1(x＞0)　→　勾配が消失しにくい
    計算が高速
1. ## <a id="">過学習</a>
    訓練データに過度に適合
    汎化性能が低い

    表現力の高さ→過学習しやすい

    正則化などで解決を図る
    1. ## <a id="">正則化</a>
        機械学習の目的：既知のデータから未知のデータを予測したい
        →既知データに対する損失関数の期待値を減少させる
        →予測値と期待値の差を最小化
        1. ## <a id="">バイアス-バリアンス分解</a>
            損失関数の期待値最小化にあたり，式要素を分解し各項から最小化を図る
            →回帰タスク（損失関数が二乗和誤差）のみ成り立つ

            バリアンス項
            →予測値の分散
            →大ならば過学習

            バイアス項
            →予測値の期待値と目的変数の期待値の差
            →大ならば未学習

            ノイズ項
            →データのノイズ
            →MLでのフィティングには無関係

            バリアンスとバイアスはトレードオフ
            基本的に学習されていることが望まれるため，バリアンスを抑えながら学習を図る
            →正則化
        1. ## <a id="">ノルムペナルティ</a>
            ノルム：ベクトルに対する距離を測る指標
            ハイパパラメータ
            $$
            ||x||_p = \left(|x_1|^p + |x_2|^p + \cdots + |x_D|^p\right)^{\frac{1}{p}}
            $$
            pの値によってL0,L1,L2,L$\infty$が存在

            パラメータが極端な値を取らないように損失関数に制限をかける

            ノルムつき損失関数＝損失関数＋$\lambda$(パラメータのLPノルム)

            ラムダ大　正則化強　過学習抑制　
            抑えすぎると精度が下がる

        1. ## <a id="">ラッソ回帰 Lasso Regression</a>
            L1ノルムによる正則化
            スパースな解を得やすい

            一般に
            通常損失関数とパラメータ制約領域の接点が最適解となりやすい

            ラッソ回帰
            領域が直線のため軸で接しやすい（それぞれのパラメータが0になることが多い）

            $$
              L_{norm}(y(X), t) = L(y(X), t) + \lambda(|w_0| + |w_1| + \cdots + |w_n|)
            $$

        1. ## <a id="">リッジ回帰 Lidge Regression</a>
            L2ノルムによる正則化
            汎化性能の高い解を得やすい

            リッジ回帰
            領域が円状なため，柔軟な値で最適解を取りやすい

            $$
              L_{norm}(y(X), t) = L(y(X), t) + \lambda\sqrt{w_0^2 + w_1^2 + \cdots + w_n^2}
            $$

        1. ## <a id="">elastic Net</a>
            ラッソ回帰とリッジ回帰の折衷案

            $$
              Lasso = \Omega(W) = (|w_0| + |w_1| + \cdots + |w_n|)
            $$
            $$
              Lidge = \Omega(W) = \sqrt{w_0^2 + w_1^2 + \cdots + w_n^2}
            $$
            $$
              elastic Net = \alpha\Omega(W) = \lambda(|w_0| + |w_1| + \cdots + |w_n|) + \frac{(1-\lambda)}{2}\sqrt{w_0^2 + w_1^2 + \cdots + w_n^2}
            $$

        1. ## <a id="">パラメータ拘束</a>
            類似したタスクのモデルのパラメータにノルムペナルティを課す
            モデルA(パラメータ$W^{(A)}$)とモデルB(パラメータ$W^{(B)}$)は類似タスク
            これらの距離を近くする
            下記項を最小化する
            $$
              \lambda\Omega(W^{(A)}), W^{(B)})=\lambda\left( |w_1^{(A)}-w_1^{(B)}|^2 + \cdots + |w_D^{(A)}-w_D^{(B)}|^2\right)^{\frac{1}{2}}
            $$

        1. ## <a id="">パラメータ共有</a>
            モデルの一部のパラメータを同じ値にする
            どこを同じにするかは開発者による
            例えば，MLPのノード間のパラメータを左右対象にする

            パラメータ共有・拘束においても，過剰な表現力に制限をかけるイメージ

        1. ## <a id="">早期終了 Early stopping</a>
            最適化への道を途中で打ち切り，パラメータ制約を行う効果がある

        1. ## <a id="">アンサンブル学習</a>
            複数のモデルを組み合わせて汎化性能向上

            | Name | 特徴 | 正則化効果 | 備考 |
            | - | - | - | - |
            | バギング | 同時多数学習モデル | varianceを下げる | 多数決モデル<br>訓練データから多数のデータセットを作りそれぞれのモデルで学習 |
            | ブースティング | 段階的改善モデル | biasを下げる | 徐々にupdate<br>前のモデルの誤った予測を重みづけ学習 |

        1. ## <a id="">ノイズによる正則化</a>
            ノイズ：ある現象の不確実性から生じるデータや情報

            ノイズを加える位置によって手法が異なる

            入力層：data augmentation
            隠れ層：dropout, dropconect
            目的変数：label smoothing
            1. ## <a id="">Data Augmentation</a>
                学習データに多様性を持たせ，汎化性能を向上させる
                回転拡大縮小切り抜きなど
            1. ## <a id="">Dropout</a>
                訓練時
                指定された割合のノードをランダムに非活性
                部分的なネットワークのアンサンブル学習
                (in PyTorch 指定した確率pに基づくベルヌーイ分布からのサンプルを持ちに消すノードを選択)

                評価時
                全てのノードを使用
                出力時には1-pを乗算（確率pで消すノードを選択しているため）

                実用性が高い
                学習パラメータが削減されるため計算コスト小さい
                ほぼ全てのモデルに適用可
                訓練データが少ないとうまくいかない傾向
            1. ## <a id="">Dropconnect</a>
                指定された割合のパラメータ（ブランチ　線）ランダムに非活性

                dropoutより優れた性能
                乱数のシードに大きく左右され再現性が困難
            1. ## <a id="">Label Smoothing ラベル平滑化</a>
                目的変数にノイズを加える

                分類タスク(2値分類)
                人のラベル付けに誤りがる可能性
                特定のカテゴリに過剰に適合しやすい（過学習しやすい）

                に対する効果
                多少のラベル付ミスを吸収
                正解カテゴリ以外にも値が入ることで，特定のカテゴリに過剰に適合することが減る

                $$
                  \{0, 0, 1, 0\}
                $$
                に対して各ラベルにノイズを付加(ノイズ*$\alpha$)
                $$
                  \{\alpha\xi_1, \alpha\xi_2, (1-\alpha) + \alpha\xi_3, \alpha\xi_4\}
                $$

    1. ## <a id="">バッチ正規化</a>
        正規化
        平均0, 分散1にスケーリングする
        効果
        スケールの異なる特徴量を同様な基準に扱える
        学習データの分布と検証データの分部生合成を維
        スケールの大きな特徴量に左右されない

        バッチ正気化
        バッチごとに正規化
        効果
        - 学習速度の向上
            - 共変量シフトの減少
            - 大きな学習率でも安定
        - 正則化効果がある
        - NNの重みの初期値に依存しづらい

        (内部)共変量シフト
        学習が難しくなる
        - 各層の入力時のbんぷが学習の過程で変化する現象
            1. パラメータは学習毎に更新
            1. 各層出力分布は学習毎に異なる
            1. 故に各層入力分布が学習毎に異なる→共変量シフトが起こる
        - 共変量シフトで学習が難しくなる理由
            - 学習率を下げる必要．（学習時間が長くなる）
            - パラメータの初期値依存性が高くなる（初期化に注意)

    1. ## <a id="">計算コスト</a>
        1. ## <a id="">高速化</a>
            GPUで並列処理高速化

            - 分散処理
                - データ並列
                    - 同期型
                        全ての並列処理で同じ勾配を用いる
                        勾配を常に一定に保つ
                    - 非同期型
                        アプローチ毎に用いる勾配が異なる
                        勾配を常に更新する
                - モデル並列
        1. ## <a id="">軽量化</a>
            1. ## <a id="">蒸留</a>
                学習済教師モデルの入出力を，軽量な生徒モデルで学習
                soft, hard target lossを最小化
                精度は落ちる反面，軽量なモデルで計算資源を大幅に削減

                soft target loss
                教師モデルと生徒モデルの出力の損失
                hard target loss
                生徒モデルの入出力分布の損失

                知識の蒸留
                精度の高い教師モデルは，粒度の細かい重要な知識を反映できる

                例）猫・犬・ハムスター・へびに分類
                {1, 0, 0, 0}に対して{0.85, 0.1, 0.04, 0.01}を教師モデルが出力
                猫には耳があり，丸い瞳
                犬には多少にているが，蛇には程遠い．→粒度の細かい知識

            1. ## <a id="">枝刈 Pruning</a>
                寄与の小さい重みを0にする（データの流れを切る）
                （値の小さい重みを0にする）

                学習の繰り返しの中で枝刈を実行し，パラメータ削減→精度を保ちつつモデル軽量化

            1. ## <a id="">量子化</a>
                浮動小数点で表現されるパラメータを低ビットで表現（近似）
                精度を落とさずモデル圧縮

                32bitを上位16bitで表現　など

      https://www.anarchive-beta.com/entry/2020/08/16/180000

      https://qiita.com/hikobotch/items/78b53de44069fb19d311

## <a id = "cp5">Chapter 5</a>
1. ## <a id="">画像認識</a>
    - 画像分類
    - 物体検出
    - セグメンテーション

1. ## <a id="">CNN</a>
    1. ## <a id="">畳み込み</a>
        複数チャネル
            カーネルを入力の次元分用意（カラー画像なら3カーネル）
            出力は各チャネルの総和

        複数カーネル
            前段のカーネルをn個用意
            出力が1次元増える

        ミニバッチ処理
            全段の出力がミニバッチ回数分増えそう，出力次元が1次元増える

        - メリット
            - 疎結合
                画像データ特有の特徴を考慮
                特に，離れた陽うくセル同士の関係を無視
            - パラメータ共有
                同じ重みのカーネルを使い回し，メモリ使用量を抑制
        - デメリット
            - データ加工技術は含まれない
                スケーリングや回転といった画像変換はできない
                回転された画像を別途用意

    1. ## <a id="">ハイパーパラメータ</a>
        1. ## <a id="">パディング</a>
            $$
              out = (H + padding*2 - Filter)/stride + 1
            $$
            - メリット
                - 端のデータの抽出
                    パディングがないと，恥の畳み込み回数が少なくなる→重要度が下がる
                - データサイズを調整可

    1. ## <a id="">プーリング</a>
        情報抽出

        学習パラメータなし
            最大値や平均値をとるだけ（マックスプーリングが主，特徴を取りやすいため）
        チャネル数が変化しない
            チャネル毎に独立な計算
        微小な一変化にロバスト

    1. ## <a id="">im2col</a>
        入力データのカーネル適用箇所をバッチサイズ方向に切り出し，それらを行方向に並べる

        カーネルを行方向に展開し，各カーネルを列方向に並べる

        内積を取り，整形して出力データの形にする

        行列計算に帰着（大きなマトリクスの計算を高速に）

    1. ## <a id="">画像における正規化</a>

        1. ## <a id="">batch normalization</a>
            これによりDLの精度が爆発的に向上

            パラメータの勾配計算は，他のパラメータに影響が出ない前提
            偏微分をし，損失を減らす方向へ計算している

            データは適度な広がり・多様性がある方がいい（ガウス分布に沿うような）
            →さまざまなパターンを学習できるため
            →偏ったデータでは勾配が消失する可能性

            ネットワークが深いと非線形変換が何度も行われ，各層の入力データの分布が大きく変わる（内部の共変量シフト）
            →学習が進まない
            →パラメータ初期値に注意を払う必要性

            よって，各ノードの値をミニバッチ単位で正規化（パラメータのスケールを揃える）

            線形変換-非線形変換の間で行われることが多い
            →FC - BN - ReLU - FC - BV - ReLU のように

            パラメータ初期値に払う注意が小さくなる
            正則化の効果も持つ（L2正則化やDropoutの必要性がsちいさくなる）
            バッチサイズが小さすぎると機能しにくい

            スケーリング・シフトを行う
            →必ず平均0分散1になるよりは，学習にあった分布にしたい
            →$\gamma, \beta$の学習によって決まる項を組み合わせ最適な分布にする

            テスト時
            全訓練データ（フルバッチ）の平均・分散で正規化
            →テストデータでやると，１つの予測だけの際に使えない
            ミニバッチの平均・分散と移動平均でフルバッチの平均・分散を推定
            $$
              \mu_{new} = m\mu_{old} + (1 - m)\mu
            $$

        1. ## <a id="">layer normalization</a>
            同じ層のニューロン間で正規化
            一つのサンプルに対して全てのチャネルにまたがって行う
            バッチ正規化と異なり，トレーニング・テストで同じ計算を実行
            オンライン学習やRNNに拡張（1サンプルに対して行うため）

        1. ## <a id="">instance normalization</a>
            各チャネルで独立に画像に対して行う
            画像生成の分野でバッチ正規化の代替として注目
            画像以外の分野へは拡張しづらい
            バッチサイズが十分であれば，バッチ正規化のみで十分である

        1. ## <a id="">group normalization</a>
            チャネルをG個にグルーピングし，layer, instance normalizationの中間的な処理を行う
            物体検出やセグメンテーションで効果を発揮

## <a id = "cp6">Chapter 6</a>
1. ## <a id="">RNN</a>
    回帰型NN

    時系列データの処理
    →循環構造
    →出力を入力に戻す
    →BPができない
    →過去の中間層の情報を次の入力に加える（ループの展開）
    →流れが一方通行になったので（循環でない）BPができる
    →BPTT(Back Propagation Through Time)

    1. ## <a id="">順伝播</a>
        $t$番目の入力と$t-1$層の出力が$t$層の入力となり，それぞれに重みとバイアスを計算し$t+1$層の入力へとつなげる．
        予測値算出・損失計算ではこの出力を活性化関数に通し，ラベルと比較する
        $$
          h_{next} = Act(x_t W_x + h_{pre} W_h + b)\\
          {\hat y_t} = Act(h_{next} W_o + c)
        $$

    1. ## <a id="">BPTTと教師強制</a>
        BPTT
        時間軸方向の逆伝播

        BPTTの課題
        - 並列処理が不可能
        - 全時刻の中間状態を保存→メモリコストが高い

        教師強制
        前層の中間層の代わりに前層の正解ラベルを用いる
        →計算コスト大幅減
        →並列処理可能（時系列的関係を切り離して学習可能）
        - 参照する前層の情報
            - 通常のRNN：前時刻のRNNユニットの状態（訓練・テスト時）
            - 教師強制
                - 訓練時：前時刻の正解ラベル
                - テスト時：前時刻の出力層の状態

        Truncated BPTT
        通常BPTTの全中間層保存によるメモリコストを改善
        FPの接続は切らず，BPの接続を切る
        →ユニット単位でのBPを実行できる

    1. ## <a id="">深層回帰</a>
        RNNで回帰を深くし，予測能力を高めたい

        - 階層別に回帰
            RNNの状態を複数の層に分解
            各層で回帰的な結合を持たせる
            →下部の層が入力データをより適切な隠れ層の状態変換できる
        - 中間層でより深い接続
            RNNを3つの演算ブロックに切り分け，各ブロックで深い計算を持たせる（MLPなど）
            - 入力 - 隠れ層
            - 隠れ層 - 隠れ層
            - 隠れ層 - 出力層
        - スキップ接続
            3ブロックで深層化することで最適化が困難に
            →前層よりも前の状態と接続し，パラメータ数を抑える
            →データの最短経路が短くなり最適化しやすくなる

1. ## <a id="">再帰型RNN (Tree-RNN)</a>
    回帰結合型NNのもう一つの一般形
    （最近の使用例は少ない）

    子の表現特徴ベクトルを用いて親の表現特徴ベクトルを計算

    応用例
    - 自然言語処理
    - プログラミング言語の意味解析

    - 回帰型NN
        - RNN (Recurrent Neural Network)
            入力を前（あるいは後）から順番に受け取り，表現ベクトルを構成
    - 再帰型NN
        - Tree-RNN
            入力を木構造に沿って処理し，表現ベクトルを構成

    再帰型RNNもRNNと記載されることもあるので内容に注意

1. ## <a id="">長期依存性の解消　LSTM</a>
    長期依存性
    言語処理などにおいて，予測位置から遠い入力が予測に影響することがある
    →通常RNNでは位置が遠ければ依存性も低くなる
    →長期的な依存関係を学習するために「勾配爆発・勾配消失」の解決が必要

    - 勾配爆発
        各時刻でのBPの度に$W_f (if\,\,>1)$が乗されると，勾配が指数関数的に大きくなる
        - 勾配クリッピング
            BPにて勾配の上限を設定
            勾配ベクトル$\Delta\omega^{(t)}$のノルム(L2が一般的)が上限値$g$を超えた時，下式でパラメータ更新の大きさを調整
            $$
              \Delta\omega^{(t)} = \frac{g}{||\Delta\omega^{(t)}||}\Delta\omega^{(t)}
            $$

    - 勾配消失
        各時刻でのBPの度に活性化関数の微分が乗されるので，勾配が指数関数的に小さくなる
        （ReLUを除く）
        - スキップ接続・Leaky接続
            - スキップ接続(skip connection)
                隠れ層の状態をより先の層へ伝える
                →粗い時間スケールで動作し，遠い過去から現在までの情報伝達を効率化
                →これまで捉えられなかった長期依存性に希望がさす
                →通常の接続とスキップ接続両者が存在するため，勾配爆発の可能性は残る
            - Leaky接続
                前時刻からの入力を$\alpha$倍，入力層からの接続を$1-\alpha$倍して接続
                $\alpha$が1に近ければ，過去の記憶を長期間記憶
                $\alpha$が0に近ければ，過去の記憶は急速に破棄される
                $\alpha$は初期値で
                何らかの分布からサンプリングし固定
                適当な値として学習
                のいずれか
                Leakyユニットで異なる時間スケールを持つことは，長期依存性を扱う上で役に立つ
        - ゲート付きRNN
            記憶すべき情報を記憶しきれない
            →メモ（記憶セル）を追加
            →ユニットに入力層，前の隠れ層，前の記憶セルを入力
            →次の隠れ層，記憶セル(CEC)を出力
            （記憶セルは活性化関数を通さないので，勾配消失を防ぐことができる）
            →LSTM
            - 忘却ゲート forget gate
                CECから不要な記憶を忘却
                $$
                  f = \sigma\left( x_t W_x^{(f)} + h_{pre} W_h^{(f)} + b^{(f)}\right)\\
                  c_{pre} = f\odot c_{pre}
                $$
                $\sigma$はsigmoid関数（0~1）で$c_{pre}$の情報を削ぎ落とす
            - インプットゲート input gate
                情報を取捨選択し，CECにメモ
                $$
                  g = \textrm{tanh}\left( x_t W_x^{(g)} + h_{pre} W_h^{(g)} + b^{(g)}\right)\\
                  i = \sigma\left( x_t W_x^{(i)} + h_{pre} W_h^{(i)} + b^{(i)}\right)\\
                  c_{pre} += g\odot i
                $$
                $g$：記憶する情報
                $i$：どれだけメモするかの割合
                もともとあった情報に足すだけ
            - アウトプットゲート output gate
                CECの情報のうち，次の隠れそうにどの程度流すか調整
                $$
                  o = \sigma\left( x_t W_x^{(o)} + h_{pre} W_h^{(o)} + b^{(o)}\right)\\
                  h_{next} = o\odot \textrm{tanh}(c_{pre})
                $$
                $o$は0~1なのでCECをどれだけ次の層に渡すか調整される
            - 補足　ピープホール付きLSTM
                各ゲートでCECを覗き見るLSTM
        - GRU
            LSTMの表現力を保ちつつ，計算コストを低減
            - 残った機能
                隠れ状態に忘却機能と記憶機能を付与
                →勾配消失が起きづらい
            - 失った機能
                忘却・記憶機能がトレードオフ
                CECがなく，メモができない
                →過去の情報が残りづらい

            - reset gate
                過去の隠れ状態をどれだけ反映させるか
                $$
                  r = \sigma\left( x_t W_x^{(r)} + h_{pre} W_h^{(r)} + b^{(r)}\right)\\
                  h_{reset} = r\odot h_{pre}
                $$
                LSTMの忘却でゲートと同様の動き
            - update gate
                $$
                  \tilde{h} = \textrm{tanh}\left( x_t W_x + h_{reset} W_h + b\right)\\
                  z = \sigma\left( x_t W_x^{(z)} + h_{pre} W_h^{(z)} + b^{(z)}\right)\\
                  h_{next} = (1-z)\odot h_{pre} + z\odot \tilde{h}
                $$
                $\textrm{tanh}$：記憶する情報
                $\sigma$：記憶する割合
                $z$：$\sigma$
                $(1-z)\odot h_{pre}$：forget機能
                $z\odot \tilde{h}$：input機能

                forget, inputがトレードオフ

    - RNN系ユニットまとめ
        - simple RNN
            時系列データを用いる
            過去の情報を循環
        - LSTMユニット
            長期依存性（特に勾配消失）の解消
            CECによるメモを導入
        - GRUユニット
            LSTMの計算コスト低減

1. ## <a id="">双方向RNN</a>
    順方向RNN，逆方向RNNの結果をマージ
    - メリット
        後ろからの文脈情報を得られる
        →RNNよりも精度が向上することも

    出力と隠れ層の次元が単方向と比べ倍になる
    →順・逆方向の結果それぞれを保持するため

1. ## <a id="">RNN アーキテクチャ</a>
    1. ## <a id="">双方向伝播</a>
        双方向RNNは，simple RNNユニットを二つ重ねて
        互いに逆方向の伝播をさせる
        →ユニットを取り替え，双方向LSTMも可能

    1. ## <a id="">ユニット数を増やす</a>
        どのユニットもユニット数を増やしてNNを深くすることが可能
        縦横に伸ばせる
        →計算コスト高くなる
    
